#!/usr/bin/env python3
"""
DINO ëª¨ë¸ ì„œë²„
Flutter ì•±ì—ì„œ í¬ë¡­ëœ ì´ë¯¸ì§€ë¥¼ ë°›ì•„ DINO ëª¨ë¸ë¡œ ë¶„ë¥˜í•˜ëŠ” HTTP ì„œë²„
"""

import argparse
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import io
import base64
from flask import Flask, request, jsonify
from flask_cors import CORS
import numpy as np
import cv2
import os
from datetime import datetime

# live.pyì—ì„œ DINOv2Classifier í´ë˜ìŠ¤ ì¬ì‚¬ìš©
class DINOv2Classifier(nn.Module):
    """DINOv2 ë¶„ë¥˜ ëª¨ë¸"""
    def __init__(self, backbone, embed_dim, num_classes=2):
        super().__init__()
        self.backbone = backbone
        self.classifier = nn.Sequential(
            nn.Linear(embed_dim, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, x):
        features = self.backbone(x)
        return self.classifier(features)


app = Flask(__name__)
CORS(app)  # Flutter ì•±ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ CORS í—ˆìš©

# ì „ì—­ ë³€ìˆ˜
models = {}
device = 'cuda' if torch.cuda.is_available() else 'cpu'
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                       std=[0.229, 0.224, 0.225])
])


def load_dino_model(model_path, model_size='small', num_classes=2):
    """DINOv2 ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
    checkpoint = torch.load(model_path, map_location=device)
    config = checkpoint.get('config', {})
    
    model_size = config.get('model_size', model_size)
    num_classes = config.get('num_classes', num_classes)
    
    # ë°±ë³¸ ë¡œë“œ
    model_map = {
        'small': ('dinov2_vits14', 384),
        'base': ('dinov2_vitb14', 768),
        'large': ('dinov2_vitl14', 1024),
        'giant': ('dinov2_vitg14', 1536)
    }
    model_name, embed_dim = model_map.get(model_size, ('dinov2_vits14', 384))
    
    backbone = torch.hub.load('facebookresearch/dinov2', model_name)
    model = DINOv2Classifier(backbone, embed_dim, num_classes)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()
    
    return model, num_classes


@app.route('/health', methods=['GET'])
def health():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return jsonify({
        'status': 'ok',
        'device': device,
        'models_loaded': list(models.keys())
    })


@app.route('/save_frame', methods=['POST'])
def save_frame():
    """
    ì •ì§€ëœ í”„ë ˆì„ ì´ë¯¸ì§€ë¥¼ ì„œë²„ì— ì €ì¥í•˜ê³  YOLO ì¢Œí‘œë¡œ í¬ë¡­
    Request:
        - image: ë°”ì´ë„ˆë¦¬ ì´ë¯¸ì§€ íŒŒì¼
        - detections: JSON ë¬¸ìì—´ (YOLO íƒì§€ ê²°ê³¼)
        - model_type: 'bolt' ë˜ëŠ” 'door'
        - filename: ì €ì¥í•  íŒŒì¼ëª… (ì„ íƒì‚¬í•­)
    Response:
        - success: bool
        - filepath: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        - cropped_files: í¬ë¡­ëœ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    try:
        if 'image' not in request.files:
            return jsonify({'error': 'image file is required'}), 400
        
        file = request.files['image']
        image_bytes = file.read()
        
        # ì´ë¯¸ì§€ ë””ì½”ë”©
        import numpy as np
        nparr = np.frombuffer(image_bytes, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if frame is None:
            return jsonify({'error': 'Failed to decode image'}), 400
        
        # íŒŒì¼ëª… ìƒì„±
        filename = request.form.get('filename')
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
            filename = f"frozen_frame_{timestamp}.jpg"
        
        # image í´ë”ì— ì •ì§€ í”„ë ˆì„ ì €ì¥
        image_dir = os.path.join(os.getcwd(), 'image')
        os.makedirs(image_dir, exist_ok=True)
        image_filepath = os.path.join(image_dir, filename)
        cv2.imwrite(image_filepath, frame)
        print(f"  [DINO Server] ì •ì§€ í”„ë ˆì„ ì €ì¥: {image_filepath} ({len(image_bytes)} bytes)")
        
        # YOLO ì¢Œí‘œê°’ íŒŒì‹± ë° í¬ë¡­
        cropped_files = []
        detections_json = request.form.get('detections')
        model_type = request.form.get('model_type', 'bolt')
        
        # ìº¡ì²˜ëœ í”„ë ˆì„ í¬ê¸°
        frame_h, frame_w = frame.shape[:2]
        print(f"  [DINO Server] ìº¡ì²˜ëœ í”„ë ˆì„ í¬ê¸°: {frame_w}x{frame_h}")
        
        # í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì „ì†¡í•œ í”„ë ˆì„ í¬ê¸° ì •ë³´ (ë””ë²„ê¹…ìš©)
        client_frame_w = request.form.get('frame_width')
        client_frame_h = request.form.get('frame_height')
        if client_frame_w and client_frame_h:
            print(f"  [DINO Server] í´ë¼ì´ì–¸íŠ¸ê°€ ì „ì†¡í•œ í”„ë ˆì„ í¬ê¸°: {client_frame_w}x{client_frame_h}")
            if int(client_frame_w) != frame_w or int(client_frame_h) != frame_h:
                print(f"  [DINO Server] âš ï¸  ê²½ê³ : í”„ë ˆì„ í¬ê¸°ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
                print(f"    ì„œë²„ ë””ì½”ë”© í¬ê¸°: {frame_w}x{frame_h}")
                print(f"    í´ë¼ì´ì–¸íŠ¸ ì „ì†¡ í¬ê¸°: {client_frame_w}x{client_frame_h}")
        
        # í™”ë©´ í¬ê¸° ë° ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ì •ë³´ ê°€ì ¸ì˜¤ê¸° (í™”ë©´ ë³€í™˜ ì¬í˜„ìš©)
        view_width = request.form.get('view_width')
        view_height = request.form.get('view_height')
        orig_width = request.form.get('orig_width')
        orig_height = request.form.get('orig_height')
        
        crop_result = {'cropped_files': [], 'classification_results': []}
        if detections_json:
            try:
                import json
                detections = json.loads(detections_json)
                # í™”ë©´ ë³€í™˜ ì •ë³´ë¥¼ ì „ë‹¬í•˜ì—¬ ì •í™•í•œ í¬ë¡­ ìˆ˜í–‰
                crop_result = _crop_detections(
                    frame, 
                    detections, 
                    model_type,
                    view_width=int(view_width) if view_width else None,
                    view_height=int(view_height) if view_height else None,
                    orig_width=int(orig_width) if orig_width else None,
                    orig_height=int(orig_height) if orig_height else None,
                )
            except Exception as e:
                print(f"  [DINO Server] í¬ë¡­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
        
        # Voting ë¡œì§ (live.py ì°¸ê³ )
        final_result = None
        if crop_result['classification_results']:
            if model_type == 'bolt':
                # ë³¼íŠ¸: soft voting (í‰ê·  ë¶ˆëŸ‰ í™•ë¥ )
                defect_confidences = [r['defect_confidence'] for r in crop_result['classification_results']]
                avg_defect_conf = sum(defect_confidences) / len(defect_confidences) if defect_confidences else 0.0
                final_result = {
                    'is_good': avg_defect_conf < 0.5,
                    'result_text': 'ì–‘í’ˆ' if avg_defect_conf < 0.5 else 'ë¶ˆëŸ‰',
                    'avg_defect_confidence': avg_defect_conf,
                    'voting_method': 'soft'
                }
            elif model_type == 'door':
                # ë„ì–´: soft voting (í‰ê·  ë¶ˆëŸ‰ í™•ë¥ )
                defect_confidences = [r['defect_confidence'] for r in crop_result['classification_results']]
                avg_defect_conf = sum(defect_confidences) / len(defect_confidences) if defect_confidences else 0.0
                final_result = {
                    'is_good': avg_defect_conf < 0.5,
                    'result_text': 'ì–‘í’ˆ' if avg_defect_conf < 0.5 else 'ë¶ˆëŸ‰',
                    'avg_defect_confidence': avg_defect_conf,
                    'voting_method': 'soft'
                }
        
        return jsonify({
            'success': True,
            'filepath': image_filepath,
            'filename': filename,
            'size': len(image_bytes),
            'cropped_files': crop_result['cropped_files'],
            'classification_results': crop_result['classification_results'],
            'final_result': final_result
        })
    except Exception as e:
        print(f"DINO ì„œë²„ í”„ë ˆì„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


def _classify_cropped_image(cropped_img, model_key):
    """
    í¬ë¡­ëœ ì´ë¯¸ì§€ë¥¼ DINO ëª¨ë¸ë¡œ ë¶„ë¥˜ (live.pyì˜ _classify_with_dino ì°¸ê³ )
    
    Args:
        cropped_img: OpenCV ì´ë¯¸ì§€ (numpy array, BGR)
        model_key: 'bolt', 'door_high', 'door_mid', 'door_low'
    
    Returns:
        ë¶„ë¥˜ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if model_key not in models:
        return {
            'is_defect': True,
            'confidence': [0.0, 1.0],
            'pred_class': 1,
            'defect_confidence': 1.0,
            'num_classes': 2,
            'error': f'Model {model_key} not loaded'
        }
    
    if cropped_img.size == 0:
        return {
            'is_defect': True,
            'confidence': [0.0, 1.0],
            'pred_class': 1,
            'defect_confidence': 1.0,
            'num_classes': 2,
            'error': 'Empty image'
        }
    
    try:
        model, num_classes = models[model_key]
        
        # BGR -> RGB ë³€í™˜
        cropped_rgb = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB)
        pil_img = Image.fromarray(cropped_rgb)
        
        # ì „ì²˜ë¦¬ ë° í…ì„œ ë³€í™˜
        img_tensor = transform(pil_img).unsqueeze(0).to(device)
        
        # DINO ë¶„ë¥˜
        with torch.no_grad():
            outputs = model(img_tensor)
            probs = torch.softmax(outputs, dim=1)
            pred_class = torch.argmax(probs, dim=1).item()
            confidence = probs[0].cpu().numpy().tolist()
        
        # ë¶ˆëŸ‰ íŒì • (live.py ì°¸ê³ )
        if num_classes == 4:
            is_defect = (pred_class != 0)
            defect_confidence = sum(confidence[1:4]) if len(confidence) >= 4 else confidence[1] if len(confidence) >= 2 else 0.0
        else:
            is_defect = (pred_class == 1)
            defect_confidence = confidence[1] if len(confidence) >= 2 else 0.0
        
        return {
            'is_defect': is_defect,
            'confidence': confidence,
            'pred_class': pred_class,
            'defect_confidence': defect_confidence,
            'num_classes': num_classes
        }
    except Exception as e:
        print(f"  [DINO Server] ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return {
            'is_defect': True,
            'confidence': [0.0, 1.0],
            'pred_class': 1,
            'defect_confidence': 1.0,
            'num_classes': 2,
            'error': str(e)
        }


def _crop_detections(frame, detections, model_type, view_width=None, view_height=None, orig_width=None, orig_height=None):
    """
    YOLO íƒì§€ ê²°ê³¼ë¥¼ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ í¬ë¡­ ë° DINO ë¶„ë¥˜ (live.py ì°¸ê³ )
    
    í™”ë©´ì— ê·¸ë ¤ì§„ ë°•ìŠ¤ì™€ ì •í™•íˆ ê°™ì€ ì˜ì—­ì„ í¬ë¡­í•˜ê¸° ìœ„í•´:
    1. ì´ë¯¸ì§€ë¥¼ í™”ë©´ì— ê·¸ë ¤ì§„ ê²ƒì²˜ëŸ¼ ë³€í™˜ (ìŠ¤ì¼€ì¼ + ì˜¤í”„ì…‹)
    2. ë³€í™˜ëœ ì´ë¯¸ì§€ì—ì„œ YOLO ì¢Œí‘œë¡œ í¬ë¡­
    3. í¬ë¡­ëœ ì´ë¯¸ì§€ë¥¼ ì›ë³¸ ë¹„ìœ¨ë¡œ ë³µì›
    
    Args:
        frame: OpenCV ì´ë¯¸ì§€ (numpy array)
        detections: YOLO íƒì§€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        model_type: 'bolt' ë˜ëŠ” 'door'
        view_width: í™”ë©´ ë„ˆë¹„ (ì„ íƒì‚¬í•­)
        view_height: í™”ë©´ ë†’ì´ (ì„ íƒì‚¬í•­)
        orig_width: YOLO ì›ë³¸ ì´ë¯¸ì§€ ë„ˆë¹„ (ì„ íƒì‚¬í•­)
        orig_height: YOLO ì›ë³¸ ì´ë¯¸ì§€ ë†’ì´ (ì„ íƒì‚¬í•­)
    
    Returns:
        ë”•ì…”ë„ˆë¦¬: {
            'cropped_files': í¬ë¡­ëœ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸,
            'classification_results': ë¶„ë¥˜ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        }
    """
    cropped_files = []
    classification_results = []
    
    try:
        # í”„ë ˆì„ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
        frame_h, frame_w = frame.shape[:2]
        
        # í™”ë©´ ë³€í™˜ ì •ë³´ ê³„ì‚° (í™”ë©´ì— ë°•ìŠ¤ë¥¼ ê·¸ë¦´ ë•Œ ì‚¬ìš©í•˜ëŠ” ë³€í™˜ ì¬í˜„)
        use_screen_transform = False
        scale = 1.0
        dx = 0.0
        dy = 0.0
        
        if view_width and view_height and orig_width and orig_height:
            # í™”ë©´ì— ë°•ìŠ¤ë¥¼ ê·¸ë¦´ ë•Œ ì‚¬ìš©í•˜ëŠ” ë³€í™˜ ê³„ì‚°
            # Android YOLOView.kt ì°¸ê³ :
            # scale = max(vw/iw, vh/ih)
            # dx = (vw - iw*scale) / 2
            # dy = (vh - ih*scale) / 2
            scale_x = view_width / orig_width
            scale_y = view_height / orig_height
            scale = max(scale_x, scale_y)
            
            scaled_w = orig_width * scale
            scaled_h = orig_height * scale
            dx = (view_width - scaled_w) / 2.0
            dy = (view_height - scaled_h) / 2.0
            
            use_screen_transform = True
            print(f"  [DINO Server] í™”ë©´ ë³€í™˜ ì •ë³´:")
            print(f"    ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {orig_width}x{orig_height}")
            print(f"    í™”ë©´ í¬ê¸°: {view_width}x{view_height}")
            print(f"    ìŠ¤ì¼€ì¼: {scale:.6f} (scaleX={scale_x:.6f}, scaleY={scale_y:.6f})")
            print(f"    ì˜¤í”„ì…‹: dx={dx:.2f}, dy={dy:.2f}")
            print(f"    í”„ë ˆì„ í¬ê¸°: {frame_w}x{frame_h}")
        
        # debug_crop í´ë” ìƒì„±
        debug_crop_dir = os.path.join(os.getcwd(), 'debug_crop')
        os.makedirs(debug_crop_dir, exist_ok=True)
        
        if model_type == 'bolt':
            # bolt í´ë” ìƒì„±
            bolt_dir = os.path.join(debug_crop_dir, 'bolt')
            os.makedirs(bolt_dir, exist_ok=True)
            
            # ë³¼íŠ¸ í´ë˜ìŠ¤ ë§¤í•‘ (live.py ì°¸ê³ )
            bolt_class_names = {
                0: 'bolt_frontside',
                1: 'bolt_side',
                2: 'sedan (trunklid)',
                3: 'suv (trunklid)',
                4: 'hood',
                5: 'long (frontfender)',
                6: 'mid (frontfender)',
                7: 'short (frontfender)',
            }
            
            # í”„ë ˆì„ ì°¾ê¸°
            frame_detection = None
            bolt_detections = []
            
            for det in detections:
                class_index = det.get('classIndex', -1)
                if class_index >= 2 and class_index <= 7:  # í”„ë ˆì„
                    frame_detection = det
                elif class_index == 0 or class_index == 1:  # ë³¼íŠ¸
                    bolt_detections.append(det)
            
            if frame_detection:
                frame_class_index = frame_detection.get('classIndex', 2)
                frame_name = bolt_class_names.get(frame_class_index, 'unknown')
                frame_bbox = frame_detection.get('boundingBox', {})
                
                # í”„ë ˆì„ ë‚´ ë³¼íŠ¸ë§Œ í¬ë¡­ (live.pyì˜ _inspect_bolt ì°¸ê³ )
                bolts_in_frame = []
                for bolt in bolt_detections:
                    bolt_bbox = bolt.get('boundingBox', {})
                    bolt_center = [
                        (bolt_bbox.get('left', 0) + bolt_bbox.get('right', 0)) / 2,
                        (bolt_bbox.get('top', 0) + bolt_bbox.get('bottom', 0)) / 2,
                    ]
                    
                    # í”„ë ˆì„ ë‚´ë¶€ì— ìˆëŠ”ì§€ í™•ì¸ (ê°„ë‹¨í•œ AABB ì²´í¬)
                    if (frame_bbox.get('left', 0) <= bolt_center[0] <= frame_bbox.get('right', 0) and
                        frame_bbox.get('top', 0) <= bolt_center[1] <= frame_bbox.get('bottom', 0)):
                        bolts_in_frame.append(bolt)
                
                # ê° ë³¼íŠ¸ í¬ë¡­ (live.py: bolt_{i+1}_{frame_name}_{timestamp}.jpg)
                for i, bolt in enumerate(bolts_in_frame):
                    # âš ï¸ ì¤‘ìš”: ì •ê·œí™” ì¢Œí‘œë§Œ ì‚¬ìš© (í™”ë©´ í¬ê¸°ì™€ ë¬´ê´€í•˜ê²Œ ì •í™•í•œ í¬ë¡­ì„ ìœ„í•´)
                    normalized_bbox = bolt.get('normalizedBox', {})
                    if not normalized_bbox:
                        print(f"  [DINO Server] âš ï¸  ë³¼íŠ¸ #{i+1}: ì •ê·œí™” ì¢Œí‘œê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                        continue
                    
                    # YOLOê°€ ë‚´ë±‰ì€ ì •ê·œí™” ì¢Œí‘œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    norm_left = float(normalized_bbox.get('left', 0))
                    norm_top = float(normalized_bbox.get('top', 0))
                    norm_right = float(normalized_bbox.get('right', 0))
                    norm_bottom = float(normalized_bbox.get('bottom', 0))
                    
                    if use_screen_transform:
                        # í™”ë©´ì— ê·¸ë ¤ì§„ ë°•ìŠ¤ì™€ ì •í™•íˆ ê°™ì€ ì˜ì—­ì„ í¬ë¡­í•˜ê¸° ìœ„í•´:
                        # 1. ì •ê·œí™” ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ê¸°ì¤€ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
                        orig_x1 = norm_left * orig_width
                        orig_y1 = norm_top * orig_height
                        orig_x2 = norm_right * orig_width
                        orig_y2 = norm_bottom * orig_height
                        
                        # 2. í™”ë©´ ì¢Œí‘œë¡œ ë³€í™˜ (í™”ë©´ì— ê·¸ë¦´ ë•Œ ì‚¬ìš©í•˜ëŠ” ë³€í™˜)
                        screen_x1 = orig_x1 * scale + dx
                        screen_y1 = orig_y1 * scale + dy
                        screen_x2 = orig_x2 * scale + dx
                        screen_y2 = orig_y2 * scale + dy
                        
                        # 3. í™”ë©´ ì¢Œí‘œë¥¼ í”„ë ˆì„ í¬ê¸°ì— ë§ê²Œ ìŠ¤ì¼€ì¼ë§
                        # í”„ë ˆì„ í¬ê¸°ì™€ í™”ë©´ í¬ê¸°ì˜ ë¹„ìœ¨ ê³„ì‚°
                        frame_scale_x = frame_w / view_width
                        frame_scale_y = frame_h / view_height
                        
                        # í”„ë ˆì„ ì¢Œí‘œë¡œ ë³€í™˜
                        x1 = int(screen_x1 * frame_scale_x)
                        y1 = int(screen_y1 * frame_scale_y)
                        x2 = int(screen_x2 * frame_scale_x)
                        y2 = int(screen_y2 * frame_scale_y)
                        
                        print(f"  [DINO Server] ë³¼íŠ¸ #{i+1} í¬ë¡­ ì¢Œí‘œ (í™”ë©´ ë³€í™˜ ì ìš©):")
                        print(f"    YOLO ì •ê·œí™” ì¢Œí‘œ: left={norm_left:.6f}, top={norm_top:.6f}, right={norm_right:.6f}, bottom={norm_bottom:.6f}")
                        print(f"    ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œ: ({orig_x1:.2f}, {orig_y1:.2f}, {orig_x2:.2f}, {orig_y2:.2f})")
                        print(f"    í™”ë©´ ì¢Œí‘œ: ({screen_x1:.2f}, {screen_y1:.2f}, {screen_x2:.2f}, {screen_y2:.2f})")
                        print(f"    í”„ë ˆì„ ì¢Œí‘œ: ({x1}, {y1}, {x2}, {y2})")
                    else:
                        # í™”ë©´ ë³€í™˜ ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
                        x1_float = norm_left * frame_w
                        y1_float = norm_top * frame_h
                        x2_float = norm_right * frame_w
                        y2_float = norm_bottom * frame_h
                        
                        x1 = int(x1_float)
                        y1 = int(y1_float)
                        x2 = int(x2_float)
                        y2 = int(y2_float)
                        
                        print(f"  [DINO Server] ë³¼íŠ¸ #{i+1} í¬ë¡­ ì¢Œí‘œ (ê¸°ë³¸ ë³€í™˜):")
                        print(f"    YOLO ì •ê·œí™” ì¢Œí‘œ: left={norm_left:.6f}, top={norm_top:.6f}, right={norm_right:.6f}, bottom={norm_bottom:.6f}")
                        print(f"    í”„ë ˆì„ í¬ê¸°: {frame_w}x{frame_h}")
                        print(f"    ê³„ì‚°(float): x1={x1_float:.2f}, y1={y1_float:.2f}, x2={x2_float:.2f}, y2={y2_float:.2f}")
                        print(f"    ë³€í™˜ëœ í”½ì…€ ì¢Œí‘œ: ({x1}, {y1}, {x2}, {y2})")
                    
                    # ì´ë¯¸ì§€ ê²½ê³„ í™•ì¸ ë° ë³´ì •
                    x1 = max(0, min(x1, frame_w - 1))
                    y1 = max(0, min(y1, frame_h - 1))
                    x2 = max(x1 + 1, min(x2, frame_w))
                    y2 = max(y1 + 1, min(y2, frame_h))
                    
                    print(f"    ê²½ê³„ ë³´ì • í›„: ({x1}, {y1}, {x2}, {y2})")
                    
                    if x2 > x1 and y2 > y1:
                        # NumPy ë°°ì—´ ìŠ¬ë¼ì´ì‹±ìœ¼ë¡œ í¬ë¡­ (flip ì—†ì´ ì›ë³¸ ê·¸ëŒ€ë¡œ)
                        cropped = frame[y1:y2, x1:x2]
                        if cropped.size > 0:
                            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                            crop_filename = f"bolt_{i+1}_{frame_name}_{timestamp}.jpg"
                            crop_filepath = os.path.join(bolt_dir, crop_filename)
                            cv2.imwrite(crop_filepath, cropped)
                            cropped_files.append(crop_filepath)
                            print(f"  [DINO Server] ë³¼íŠ¸ í¬ë¡­ ì €ì¥: {crop_filepath} (í¬ê¸°: {cropped.shape[1]}x{cropped.shape[0]})")
                            
                            # DINO ëª¨ë¸ë¡œ ë¶„ë¥˜ (live.pyì˜ _inspect_bolt ì°¸ê³ )
                            print(f"  [DINO Server] ë³¼íŠ¸ #{i+1} DINO ë¶„ë¥˜ ì‹œì‘...")
                            result = _classify_cropped_image(cropped, 'bolt')
                            result['bolt_index'] = i + 1
                            result['frame_name'] = frame_name
                            result['crop_filepath'] = crop_filepath
                            classification_results.append(result)
                            
                            result_text = "ë¶ˆëŸ‰" if result['is_defect'] else "ì–‘í’ˆ"
                            conf_display = result['confidence'][result['pred_class']]
                            print(f"  [DINO Server] ë³¼íŠ¸ #{i+1}: {result_text} (ì‹ ë¢°ë„: {conf_display:.2%})")
        
        elif model_type == 'door':
            # door í´ë” ìƒì„±
            door_dir = os.path.join(debug_crop_dir, 'door')
            os.makedirs(door_dir, exist_ok=True)
            
            # door íŒŒíŠ¸ë³„ë¡œ ë¶„ë¥˜
            parts = {'high': [], 'mid': [], 'low': []}
            
            for det in detections:
                class_name = det.get('className', '').lower()
                if class_name in parts:
                    parts[class_name].append(det)
            
            # ê° íŒŒíŠ¸ í¬ë¡­ (live.py: frontdoor_{part}_{timestamp}.jpg)
            for part in ['high', 'mid', 'low']:
                if parts[part]:
                    part_det = parts[part][0]  # ì²« ë²ˆì§¸ íƒì§€ë§Œ ì‚¬ìš©
                    # âš ï¸ ì¤‘ìš”: ì •ê·œí™” ì¢Œí‘œë§Œ ì‚¬ìš© (í™”ë©´ í¬ê¸°ì™€ ë¬´ê´€í•˜ê²Œ ì •í™•í•œ í¬ë¡­ì„ ìœ„í•´)
                    normalized_bbox = part_det.get('normalizedBox', {})
                    if not normalized_bbox:
                        print(f"  [DINO Server] âš ï¸  ë„ì–´ {part.upper()}: ì •ê·œí™” ì¢Œí‘œê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                        continue
                    
                    # YOLOê°€ ë‚´ë±‰ì€ ì •ê·œí™” ì¢Œí‘œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    norm_left = float(normalized_bbox.get('left', 0))
                    norm_top = float(normalized_bbox.get('top', 0))
                    norm_right = float(normalized_bbox.get('right', 0))
                    norm_bottom = float(normalized_bbox.get('bottom', 0))
                    
                    if use_screen_transform:
                        # í™”ë©´ì— ê·¸ë ¤ì§„ ë°•ìŠ¤ì™€ ì •í™•íˆ ê°™ì€ ì˜ì—­ì„ í¬ë¡­í•˜ê¸° ìœ„í•´:
                        # 1. ì •ê·œí™” ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ê¸°ì¤€ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
                        orig_x1 = norm_left * orig_width
                        orig_y1 = norm_top * orig_height
                        orig_x2 = norm_right * orig_width
                        orig_y2 = norm_bottom * orig_height
                        
                        # 2. í™”ë©´ ì¢Œí‘œë¡œ ë³€í™˜ (í™”ë©´ì— ê·¸ë¦´ ë•Œ ì‚¬ìš©í•˜ëŠ” ë³€í™˜)
                        screen_x1 = orig_x1 * scale + dx
                        screen_y1 = orig_y1 * scale + dy
                        screen_x2 = orig_x2 * scale + dx
                        screen_y2 = orig_y2 * scale + dy
                        
                        # 3. í™”ë©´ ì¢Œí‘œë¥¼ í”„ë ˆì„ í¬ê¸°ì— ë§ê²Œ ìŠ¤ì¼€ì¼ë§
                        # í”„ë ˆì„ í¬ê¸°ì™€ í™”ë©´ í¬ê¸°ì˜ ë¹„ìœ¨ ê³„ì‚°
                        frame_scale_x = frame_w / view_width
                        frame_scale_y = frame_h / view_height
                        
                        # í”„ë ˆì„ ì¢Œí‘œë¡œ ë³€í™˜
                        x1 = int(screen_x1 * frame_scale_x)
                        y1 = int(screen_y1 * frame_scale_y)
                        x2 = int(screen_x2 * frame_scale_x)
                        y2 = int(screen_y2 * frame_scale_y)
                        
                        print(f"  [DINO Server] ë„ì–´ {part.upper()} í¬ë¡­ ì¢Œí‘œ (í™”ë©´ ë³€í™˜ ì ìš©):")
                        print(f"    YOLO ì •ê·œí™” ì¢Œí‘œ: left={norm_left:.6f}, top={norm_top:.6f}, right={norm_right:.6f}, bottom={norm_bottom:.6f}")
                        print(f"    ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œ: ({orig_x1:.2f}, {orig_y1:.2f}, {orig_x2:.2f}, {orig_y2:.2f})")
                        print(f"    í™”ë©´ ì¢Œí‘œ: ({screen_x1:.2f}, {screen_y1:.2f}, {screen_x2:.2f}, {screen_y2:.2f})")
                        print(f"    í”„ë ˆì„ ì¢Œí‘œ: ({x1}, {y1}, {x2}, {y2})")
                    else:
                        # í™”ë©´ ë³€í™˜ ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
                        x1_float = norm_left * frame_w
                        y1_float = norm_top * frame_h
                        x2_float = norm_right * frame_w
                        y2_float = norm_bottom * frame_h
                        
                        x1 = int(x1_float)
                        y1 = int(y1_float)
                        x2 = int(x2_float)
                        y2 = int(y2_float)
                        
                        print(f"  [DINO Server] ë„ì–´ {part.upper()} í¬ë¡­ ì¢Œí‘œ (ê¸°ë³¸ ë³€í™˜):")
                        print(f"    YOLO ì •ê·œí™” ì¢Œí‘œ: left={norm_left:.6f}, top={norm_top:.6f}, right={norm_right:.6f}, bottom={norm_bottom:.6f}")
                        print(f"    í”„ë ˆì„ í¬ê¸°: {frame_w}x{frame_h}")
                        print(f"    ê³„ì‚°(float): x1={x1_float:.2f}, y1={y1_float:.2f}, x2={x2_float:.2f}, y2={y2_float:.2f}")
                        print(f"    ë³€í™˜ëœ í”½ì…€ ì¢Œí‘œ: ({x1}, {y1}, {x2}, {y2})")
                    
                    # ì´ë¯¸ì§€ ê²½ê³„ í™•ì¸ ë° ë³´ì •
                    x1 = max(0, min(x1, frame_w - 1))
                    y1 = max(0, min(y1, frame_h - 1))
                    x2 = max(x1 + 1, min(x2, frame_w))
                    y2 = max(y1 + 1, min(y2, frame_h))
                    
                    print(f"    ê²½ê³„ ë³´ì • í›„: ({x1}, {y1}, {x2}, {y2})")
                    
                    if x2 > x1 and y2 > y1:
                        # NumPy ë°°ì—´ ìŠ¬ë¼ì´ì‹±ìœ¼ë¡œ í¬ë¡­ (flip ì—†ì´ ì›ë³¸ ê·¸ëŒ€ë¡œ)
                        cropped = frame[y1:y2, x1:x2]
                        if cropped.size > 0:
                            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]  # ë°€ë¦¬ì´ˆ í¬í•¨
                            crop_filename = f"frontdoor_{part}_{timestamp}.jpg"
                            crop_filepath = os.path.join(door_dir, crop_filename)
                            cv2.imwrite(crop_filepath, cropped)
                            cropped_files.append(crop_filepath)
                            print(f"  [DINO Server] ë„ì–´ {part.upper()} í¬ë¡­ ì €ì¥: {crop_filepath} (í¬ê¸°: {cropped.shape[1]}x{cropped.shape[0]})")
                            
                            # DINO ëª¨ë¸ë¡œ ë¶„ë¥˜ (live.pyì˜ _inspect_frontdoor ì°¸ê³ )
                            model_key = f'door_{part}'  # door_high, door_mid, door_low
                            print(f"  [DINO Server] ë„ì–´ {part.upper()} DINO ë¶„ë¥˜ ì‹œì‘...")
                            result = _classify_cropped_image(cropped, model_key)
                            result['part'] = part
                            result['crop_filepath'] = crop_filepath
                            classification_results.append(result)
                            
                            result_text = "ë¶ˆëŸ‰" if result['is_defect'] else "ì–‘í’ˆ"
                            conf_display = result['confidence'][result['pred_class']]
                            print(f"  [DINO Server] ë„ì–´ {part.upper()}: {result_text} (ì‹ ë¢°ë„: {conf_display:.2%})")
    
    except Exception as e:
        print(f"  [DINO Server] í¬ë¡­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    
    return {
        'cropped_files': cropped_files,
        'classification_results': classification_results
    }


@app.route('/classify', methods=['POST'])
def classify():
    """
    ì´ë¯¸ì§€ ë¶„ë¥˜ ì—”ë“œí¬ì¸íŠ¸
    Request:
        - image: base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë˜ëŠ” ë°”ì´ë„ˆë¦¬
        - model_type: 'bolt' ë˜ëŠ” 'door_high', 'door_mid', 'door_low'
        - format: 'base64' ë˜ëŠ” 'binary' (ê¸°ë³¸ê°’: 'binary')
    Response:
        - is_defect: bool
        - confidence: List[float] (ê° í´ë˜ìŠ¤ë³„ í™•ë¥ )
        - pred_class: int (ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ì¸ë±ìŠ¤)
        - defect_confidence: float (ë¶ˆëŸ‰ í™•ë¥ )
        - num_classes: int
    """
    try:
        # ëª¨ë¸ íƒ€ì… í™•ì¸
        model_type = request.form.get('model_type') or (request.json.get('model_type') if request.is_json else None)
        if not model_type:
            return jsonify({'error': 'model_type is required'}), 400
        
        # door_high, door_mid, door_lowë¥¼ doorë¡œ ë§¤í•‘í•˜ì—¬ í™•ì¸
        model_key = model_type
        if model_type.startswith('door_'):
            # door_high, door_mid, door_lowëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
            model_key = model_type
        elif model_type == 'bolt':
            model_key = 'bolt'
        
        if model_key not in models:
            return jsonify({'error': f'Model {model_key} not loaded. Available models: {list(models.keys())}'}), 404
        
        model, num_classes = models[model_key]
        
        # ì´ë¯¸ì§€ ë°›ê¸°
        image_format = request.form.get('format', 'binary')
        
        if image_format == 'base64':
            # Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
            image_data = request.json.get('image') or request.form.get('image')
            if not image_data:
                return jsonify({'error': 'image is required'}), 400
            
            # Base64 ë””ì½”ë”©
            if image_data.startswith('data:image'):
                # data:image/png;base64,xxx í˜•ì‹
                image_data = image_data.split(',')[1]
            
            image_bytes = base64.b64decode(image_data)
            image = Image.open(io.BytesIO(image_bytes))
        else:
            # ë°”ì´ë„ˆë¦¬ ì´ë¯¸ì§€
            if 'image' not in request.files:
                return jsonify({'error': 'image file is required'}), 400
            
            file = request.files['image']
            image = Image.open(io.BytesIO(file.read()))
        
        # RGB ë³€í™˜
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # ë””ë²„ê·¸: í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥ (ì„œë²„ PCì— ì €ì¥)
        # live.py ì°¸ê³ : bolt_{i+1}_{frame_name}_{timestamp}.jpg ë˜ëŠ” door_{part}_{timestamp}.jpg
        debug_crop_dir = os.path.join(os.getcwd(), 'debug_crop')
        if not os.path.exists(debug_crop_dir):
            os.makedirs(debug_crop_dir, exist_ok=True)
        
        # ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ í•˜ìœ„ í´ë” ê²°ì •
        if model_type == 'bolt':
            sub_dir = os.path.join(debug_crop_dir, 'bolt')
        elif model_type.startswith('door_'):
            sub_dir = os.path.join(debug_crop_dir, 'door')
        else:
            sub_dir = os.path.join(debug_crop_dir, 'other')
        
        if not os.path.exists(sub_dir):
            os.makedirs(sub_dir, exist_ok=True)
        
        # íŒŒì¼ëª… ìƒì„± (live.py ìŠ¤íƒ€ì¼)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]  # ë°€ë¦¬ì´ˆ í¬í•¨
        
        # ìš”ì²­ì—ì„œ íŒŒì¼ëª… ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ìˆë‹¤ë©´)
        filename_prefix = request.form.get('filename_prefix', '')
        if filename_prefix:
            filename = f"{filename_prefix}_{timestamp}.png"
        else:
            if model_type == 'bolt':
                filename = f"bolt_{timestamp}.png"
            elif model_type.startswith('door_'):
                part = model_type.replace('door_', '')
                filename = f"door_{part}_{timestamp}.png"
            else:
                filename = f"{model_type}_{timestamp}.png"
        
        crop_filepath = os.path.join(sub_dir, filename)
        
        # ì›ë³¸ í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥ (224x224 ë¦¬ì‚¬ì´ì¦ˆ ì „)
        # ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        img_array = np.array(image)
        cv2.imwrite(crop_filepath, cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
        print(f"  [ì„œë²„] í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥: {crop_filepath} (í¬ê¸°: {image.size[0]}x{image.size[1]})")
        
        # ì „ì²˜ë¦¬ ë° ì¶”ë¡ 
        img_tensor = transform(image).unsqueeze(0).to(device)
        
        with torch.no_grad():
            outputs = model(img_tensor)
            probs = torch.softmax(outputs, dim=1)
            pred_class = torch.argmax(probs, dim=1).item()
            confidence = probs[0].cpu().numpy().tolist()
        
        # ê²°ê³¼ í•´ì„
        if num_classes == 4:
            is_defect = (pred_class != 0)
            defect_confidence = sum(confidence[1:4]) if len(confidence) >= 4 else confidence[1] if len(confidence) >= 2 else 0.0
        else:
            is_defect = (pred_class == 1)
            defect_confidence = confidence[1] if len(confidence) >= 2 else 0.0
        
        return jsonify({
            'is_defect': is_defect,
            'confidence': confidence,
            'pred_class': pred_class,
            'defect_confidence': float(defect_confidence),
            'num_classes': num_classes
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


def main():
    parser = argparse.ArgumentParser(description='DINO ëª¨ë¸ ì„œë²„')
    parser.add_argument('--host', type=str, default='0.0.0.0', help='ì„œë²„ í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: 0.0.0.0)')
    parser.add_argument('--port', type=int, default=5000, help='ì„œë²„ í¬íŠ¸ (ê¸°ë³¸ê°’: 5000)')
    parser.add_argument('--device', type=str, default='cuda', choices=['cuda', 'cpu'], help='ë””ë°”ì´ìŠ¤ (ê¸°ë³¸ê°’: cuda)')
    
    # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
    parser.add_argument('--bolt-model', type=str, help='ë³¼íŠ¸ DINO ëª¨ë¸ ê²½ë¡œ')
    parser.add_argument('--door-high-model', type=str, help='ë„ì–´ High DINO ëª¨ë¸ ê²½ë¡œ')
    parser.add_argument('--door-mid-model', type=str, help='ë„ì–´ Mid DINO ëª¨ë¸ ê²½ë¡œ')
    parser.add_argument('--door-low-model', type=str, help='ë„ì–´ Low DINO ëª¨ë¸ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    global device
    device = args.device if torch.cuda.is_available() and args.device == 'cuda' else 'cpu'
    
    print(f"ğŸš€ DINO ëª¨ë¸ ì„œë²„ ì‹œì‘")
    print(f"  ë””ë°”ì´ìŠ¤: {device}")
    print(f"  í˜¸ìŠ¤íŠ¸: {args.host}")
    print(f"  í¬íŠ¸: {args.port}\n")
    
    # ëª¨ë¸ ë¡œë“œ
    if args.bolt_model:
        print(f"ğŸ”„ ë³¼íŠ¸ ëª¨ë¸ ë¡œë“œ ì¤‘: {args.bolt_model}")
        models['bolt'] = load_dino_model(args.bolt_model, num_classes=2)
        print(f"âœ“ ë³¼íŠ¸ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (2-class)\n")
    
    if args.door_high_model:
        print(f"ğŸ”„ ë„ì–´ High ëª¨ë¸ ë¡œë“œ ì¤‘: {args.door_high_model}")
        models['door_high'] = load_dino_model(args.door_high_model)
        print(f"âœ“ ë„ì–´ High ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n")
    
    if args.door_mid_model:
        print(f"ğŸ”„ ë„ì–´ Mid ëª¨ë¸ ë¡œë“œ ì¤‘: {args.door_mid_model}")
        models['door_mid'] = load_dino_model(args.door_mid_model)
        print(f"âœ“ ë„ì–´ Mid ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n")
    
    if args.door_low_model:
        print(f"ğŸ”„ ë„ì–´ Low ëª¨ë¸ ë¡œë“œ ì¤‘: {args.door_low_model}")
        models['door_low'] = load_dino_model(args.door_low_model)
        print(f"âœ“ ë„ì–´ Low ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n")
    
    if not models:
        print("âš ï¸  ê²½ê³ : ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. --bolt-model ë˜ëŠ” --door-*-model ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
    
    print(f"âœ… ì„œë²„ ì¤€ë¹„ ì™„ë£Œ! http://{args.host}:{args.port} ì—ì„œ ì‹¤í–‰ ì¤‘...\n")
    
    app.run(host=args.host, port=args.port, debug=False, threaded=True)


if __name__ == '__main__':
    main()

