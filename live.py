import argparse
import torch
import torch.nn as nn
from ultralytics import YOLO
from torchvision import transforms
from PIL import Image
import cv2
import numpy as np
import time
from datetime import datetime
import yaml
import math
from math import cos, sin
import os
import threading
import time  

class ThreadedCamera:
    """ì•ˆì „ì¥ì¹˜ê°€ ì¶”ê°€ëœ ìµœì‹  í”„ë ˆì„ ì¹´ë©”ë¼ í´ë˜ìŠ¤"""
    def __init__(self, src=0):
        self.capture = cv2.VideoCapture(src)
        self.lock = threading.Lock() # ì“°ë ˆë“œ ì¶©ëŒ ë°©ì§€
        self.status = False
        self.frame = None
        self.stopped = False
        
        # ì¹´ë©”ë¼ê°€ ì •ìƒì ìœ¼ë¡œ ì—´ë ¸ëŠ”ì§€ í™•ì¸
        if self.capture.isOpened():
            self.status, self.frame = self.capture.read()
            if self.status:
                self.thread = threading.Thread(target=self.update, args=())
                self.thread.daemon = True
                self.thread.start()
            else:
                print("âŒ ì¹´ë©”ë¼ì—ì„œ ì²« í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print(f"âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {src}")

    def update(self):
        while not self.stopped:
            if self.capture.isOpened():
                # ë²„í¼ ì—†ì´ ì½ê¸° (grab -> retrieve ë°©ì‹ì´ ë” ë¹ ë¦„)
                status, frame = self.capture.read()
                with self.lock:
                    if status:
                        self.status = status
                        self.frame = frame
                    else:
                        # ì½ê¸° ì‹¤íŒ¨ ì‹œ ì ì‹œ ëŒ€ê¸° (CPU í­ì£¼ ë°©ì§€)
                        time.sleep(0.01)
            else:
                time.sleep(0.1)

    def read(self):
        with self.lock:
            return self.status, self.frame

    def isOpened(self):
        return self.capture.isOpened()

    def release(self):
        self.stopped = True
        if hasattr(self, 'thread'):
            self.thread.join(timeout=1.0)
        self.capture.release()

    def set(self, propId, value):
        return self.capture.set(propId, value)
    
    def get(self, propId):
        return self.capture.get(propId)


class DINOv2Classifier(nn.Module):
    """DINOv2 ë¶„ë¥˜ ëª¨ë¸"""
    def __init__(self, backbone, embed_dim, num_classes=2):
        super().__init__()
        self.backbone = backbone
        self.classifier = nn.Sequential(
            nn.Linear(embed_dim, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, x):
        features = self.backbone(x)
        return self.classifier(features)


class RealtimeInspectionSystem:
    def __init__(self, mode='frontdoor', yolo_model_path=None, dino_models=None,
                 device='cuda', conf_threshold=0.25, voting_method='soft', use_obb=False, debug=False, detect_only=False):
        """
        ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ê²€ì‚¬ ì‹œìŠ¤í…œ
        """
        self.mode = mode.lower()
        self.device = device if torch.cuda.is_available() else 'cpu'
        self.conf_threshold = conf_threshold
        self.voting_method = voting_method
        self.use_obb = use_obb
        self.debug = debug
        self.detect_only = detect_only
        
        # YOLO ëª¨ë¸ ë¡œë“œ
        print(f"ğŸ”„ YOLO ëª¨ë¸ ë¡œë“œ ì¤‘: {yolo_model_path}")
        import os
        if os.path.exists(yolo_model_path):
            file_size = os.path.getsize(yolo_model_path) / (1024 * 1024)  # MB
            print(f"  ëª¨ë¸ íŒŒì¼ ê²½ë¡œ: {yolo_model_path}")
            print(f"  íŒŒì¼ í¬ê¸°: {file_size:.2f} MB")
        try:
            self.yolo_model = YOLO(yolo_model_path)
            print(f"âœ“ YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            if hasattr(self.yolo_model, 'names'):
                print(f"  - í´ë˜ìŠ¤ ìˆ˜: {len(self.yolo_model.names)}")
                print(f"  - í´ë˜ìŠ¤ ëª©ë¡: {list(self.yolo_model.names.values())}")
        except Exception as e:
            print(f"âŒ YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
        
        # DINOv2 ëª¨ë¸ ë¡œë“œ ë° í´ë˜ìŠ¤ ìˆ˜ í™•ì¸ (detect_only ëª¨ë“œê°€ ì•„ë‹ ë•Œë§Œ)
        self.dino_models = {}
        self.dino_num_classes = {}  # ê° ëª¨ë¸ì˜ í´ë˜ìŠ¤ ìˆ˜ ì €ì¥
        
        if not self.detect_only:
            if self.mode == 'frontdoor':
                for part in ['high', 'mid', 'low']:
                    print(f"ğŸ”„ DINOv2 ëª¨ë¸ ë¡œë“œ ì¤‘ ({part}): {dino_models[part]}")
                    model, num_classes = self._load_dino_model(dino_models[part])
                    self.dino_models[part] = model
                    self.dino_num_classes[part] = num_classes
            else:  # bolt
                print(f"ğŸ”„ DINOv2 ëª¨ë¸ ë¡œë“œ ì¤‘ (bolt): {dino_models['bolt']}")
                model, num_classes = self._load_dino_model(dino_models['bolt'])
                self.dino_models['bolt'] = model
                self.dino_num_classes['bolt'] = num_classes
        else:
            print(f"â„¹ï¸  ê²€ì¶œ ì „ìš© ëª¨ë“œ: DINOv2 ëª¨ë¸ ë¡œë“œ ìƒëµ")
        
        # DINOv2 ì „ì²˜ë¦¬
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        # ì¡°ê±´ ì²´í¬ ë³€ìˆ˜
        self.condition_start_time = None
        self.condition_start_frame = None  # ë¹„ë””ì˜¤ íŒŒì¼ìš© í”„ë ˆì„ ì¹´ìš´í„°
        self.condition_met = False
        self.last_valid_frame = None
        self.last_valid_detections = None
        
        # í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥ìš© ë””ë ‰í† ë¦¬ ìƒì„± (ë””ë²„ê¹…ìš©)
        self.debug_crop_dir = None
        if self.debug:
            self.debug_crop_dir = "debug_crops"
            os.makedirs(self.debug_crop_dir, exist_ok=True)
            print(f"  - ë””ë²„ê·¸ í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ: {self.debug_crop_dir}/")
        
        # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        if self.mode == 'frontdoor':
            self.required_duration = 3.0  # 3ì´ˆ
        else:  # bolt
            self.required_duration = 3.0  # 3ì´ˆ
        
        # YOLO í´ë˜ìŠ¤ ë§¤í•‘ (bolt ëª¨ë“œìš©)
        self.bolt_class_names = {
            0: 'bolt_frontside',
            1: 'bolt_side',
            2: 'sedan (trunklid)',
            3: 'suv (trunklid)',
            4: 'hood',
            5: 'long (frontfender)',
            6: 'mid (frontfender)',
            7: 'short (frontfender)'
        }
        
        # DINO ëª¨ë“œ í™•ì¸ (configì—ì„œ ì½ì–´ì˜¨ ê°’ ì‚¬ìš©)
        self.dino_mode = None  # ë‚˜ì¤‘ì— configì—ì„œ ì„¤ì •
        
        print(f"âœ“ ì‹¤ì‹œê°„ ê²€ì‚¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"  - ëª¨ë“œ: {self.mode}")
        print(f"  - ë””ë°”ì´ìŠ¤: {self.device}")
        print(f"  - YOLO ì‹ ë¢°ë„: {self.conf_threshold}")
        if self.detect_only:
            print(f"  - ê²€ì¶œ ì „ìš© ëª¨ë“œ: í™œì„±í™” (ê²€ì‚¬ ê¸°ëŠ¥ ë¹„í™œì„±í™”)")
        else:
            print(f"  - ì¡°ê±´ ìœ ì§€ ì‹œê°„: {self.required_duration}ì´ˆ")
            print(f"  - Voting ë°©ë²•: {self.voting_method}")
        if self.use_obb:
            print(f"  - OBB ëª¨ë“œ: í™œì„±í™”")
        
        # DINO í´ë˜ìŠ¤ ìˆ˜ ì¶œë ¥ (detect_only ëª¨ë“œê°€ ì•„ë‹ ë•Œë§Œ)
        if not self.detect_only:
            if self.mode == 'frontdoor':
                for part in ['high', 'mid', 'low']:
                    num_cls = self.dino_num_classes.get(part, 2)
                    mode_text = "4-class" if num_cls == 4 else "2-class (simple)"
                    print(f"  - DINO {part}: {mode_text}")
            else:
                # ë³¼íŠ¸ëŠ” í•­ìƒ 2-class
                print(f"  - DINO bolt: 2-class (simple)")
    
    def _load_dino_model(self, model_path):
        """DINOv2 ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        import os
        if os.path.exists(model_path):
            file_size = os.path.getsize(model_path) / (1024 * 1024)  # MB
            print(f"  ëª¨ë¸ íŒŒì¼ ê²½ë¡œ: {model_path}")
            print(f"  íŒŒì¼ í¬ê¸°: {file_size:.2f} MB")
        checkpoint = torch.load(model_path, map_location=self.device)
        config = checkpoint.get('config', {})
        
        model_size = config.get('model_size', 'small')
        num_classes = config.get('num_classes', 2)
        
        # ë°±ë³¸ ë¡œë“œ
        model_map = {
            'small': ('dinov2_vits14', 384),
            'base': ('dinov2_vitb14', 768),
            'large': ('dinov2_vitl14', 1024),
            'giant': ('dinov2_vitg14', 1536)
        }
        model_name, embed_dim = model_map.get(model_size, ('dinov2_vits14', 384))
        
        backbone = torch.hub.load('facebookresearch/dinov2', model_name)
        model = DINOv2Classifier(backbone, embed_dim, num_classes)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(self.device)
        model.eval()
        
        return model, num_classes
    
    def run(self, source=0):
        """
        ì‹¤ì‹œê°„ ê²€ì‚¬ ì‹¤í–‰
        Args:
            source: ì¹´ë©”ë¼ ì†ŒìŠ¤ (0: ì›¹ìº , ë˜ëŠ” RTSP URL ë“±)
        """
        print(f"\n{'='*60}")
        print(f"ğŸ¥ ì¹´ë©”ë¼ ì‹œì‘: {source}")
        print(f"{'='*60}\n")
        
        # ë¹„ë””ì˜¤ íŒŒì¼ì¸ì§€ í™•ì¸
        is_video_file = False
        if isinstance(source, str) and (source.endswith('.mp4') or source.endswith('.avi') or 
                                         source.endswith('.mov') or source.endswith('.mkv') or
                                         source.endswith('.flv') or source.endswith('.wmv')):
            is_video_file = True
        
        # ë¹„ë””ì˜¤ íŒŒì¼ì¸ ê²½ìš° ì§ì ‘ VideoCapture ì‚¬ìš© (ëª¨ë“  í”„ë ˆì„ ì²˜ë¦¬)
        # ì¹´ë©”ë¼ëŠ” ThreadedCamera ì‚¬ìš©
        if is_video_file:
            cap = cv2.VideoCapture(source)
        else:
            cap = ThreadedCamera(source)
        
        if not cap.isOpened():
            print(f"âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {source}")
            return
        
        # ë¹„ë””ì˜¤ íŒŒì¼ì˜ FPS ë° í•´ìƒë„ ê°€ì ¸ì˜¤ê¸°
        video_fps = None
        video_width = None
        video_height = None
        total_frames = None
        video_writer = None
        output_video_path = None
        
        if is_video_file:
            video_fps = cap.get(cv2.CAP_PROP_FPS)
            video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            if video_fps > 0:
                print(f"ğŸ“¹ ë¹„ë””ì˜¤ íŒŒì¼ ê°ì§€: FPS = {video_fps:.2f}, í•´ìƒë„ = {video_width}x{video_height}, ì´ í”„ë ˆì„ = {total_frames}")
            else:
                video_fps = 30.0
                print(f"âš ï¸  ë¹„ë””ì˜¤ FPSë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ 30 FPS ì‚¬ìš©")
            
            # ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ìƒì„±
            import os
            base_name = os.path.splitext(source)[0]
            ext = os.path.splitext(source)[1]
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_video_path = f"{base_name}_output_{timestamp}{ext}"
            
            # VideoWriter ì´ˆê¸°í™” (ì—¬ëŸ¬ ì½”ë± ì‹œë„í•˜ì—¬ í˜¸í™˜ì„± í™•ë³´)
            fourcc_options = [
                ('avc1', 'H.264 (avc1)'),
                ('mp4v', 'MPEG-4 (mp4v)'),
                ('XVID', 'Xvid'),
                ('MJPG', 'Motion JPEG')
            ]
            
            video_writer = None
            for fourcc_code, codec_name in fourcc_options:
                fourcc = cv2.VideoWriter_fourcc(*fourcc_code)
                video_writer = cv2.VideoWriter(output_video_path, fourcc, video_fps, (video_width, video_height))
                if video_writer.isOpened():
                    print(f"ğŸ’¾ ì¶œë ¥ ë¹„ë””ì˜¤ ì €ì¥ ê²½ë¡œ: {output_video_path}")
                    print(f"   ì½”ë±: {codec_name}, FPS: {video_fps:.2f}, í•´ìƒë„: {video_width}x{video_height}")
                    break
                else:
                    if video_writer:
                        video_writer.release()
                    video_writer = None
            
            if video_writer is None or not video_writer.isOpened():
                print(f"âš ï¸  ë¹„ë””ì˜¤ Writer ì´ˆê¸°í™” ì‹¤íŒ¨. ë¹„ë””ì˜¤ ì €ì¥ì´ ë¶ˆê°€ëŠ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                video_writer = None
        else:
            # ì¹´ë©”ë¼ ì†ì„± ì„¤ì • (ë¹„ë””ì˜¤ íŒŒì¼ì´ ì•„ë‹ ë•Œë§Œ)
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
            cap.set(cv2.CAP_PROP_FPS, 30)
        
        # ì¹´ë©”ë¼ ì´ˆê¸°í™” ëŒ€ê¸°
        print(f"âœ“ ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ")
        if not is_video_file:
            print(f"ğŸ”„ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì¤‘...")
            time.sleep(1.0)
            
            for i in range(5):
                ret, frame = cap.read()
                if ret:
                    print(f"âœ“ ì¹´ë©”ë¼ ì¤€ë¹„ ì™„ë£Œ")
                    break
                time.sleep(0.2)
            else:
                print(f"âš ï¸  ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¬ì‹œë„ ì¤‘...")
                time.sleep(1.0)
                ret, frame = cap.read()
                if not ret:
                    print(f"âŒ ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    cap.release()
                    if video_writer:
                        video_writer.release()
                    return
        
        if self.detect_only:
            print(f"ğŸ“‹ ê²€ì¶œ ì „ìš© ëª¨ë“œ: YOLO ê²€ì¶œ ê²°ê³¼ë§Œ í‘œì‹œë©ë‹ˆë‹¤")
            print(f"   ì¢…ë£Œí•˜ë ¤ë©´ 'q' í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”\n")
        else:
            print(f"ğŸ“‹ ëŒ€ê¸° ì¤‘... (ì¡°ê±´ì´ ë§Œì¡±ë˜ë©´ ìë™ìœ¼ë¡œ ìº¡ì²˜ë©ë‹ˆë‹¤)")
            print(f"   ì¢…ë£Œí•˜ë ¤ë©´ 'q' í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”\n")
        
        try:
            frame_count = 0
            start_time = time.time()
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    if is_video_file:
                        # ë¹„ë””ì˜¤ íŒŒì¼ì´ ëë‚œ ê²½ìš°
                        elapsed_time = time.time() - start_time
                        print(f"\nğŸ“¹ ë¹„ë””ì˜¤ íŒŒì¼ ì¬ìƒ ì™„ë£Œ (ì´ {frame_count} í”„ë ˆì„ ì²˜ë¦¬, ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
                        break
                    else:
                        # ì¹´ë©”ë¼ì¸ ê²½ìš° ì¬ì‹œë„
                        print("âš ï¸  í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¬ì‹œë„ ì¤‘...")
                        for retry in range(3):
                            time.sleep(0.5)
                            ret, frame = cap.read()
                            if ret:
                                break
                        if not ret:
                            print("âŒ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨.")
                            break
                
                frame_count += 1
                
                # ë¹„ë””ì˜¤ íŒŒì¼ì¸ ê²½ìš° ì§„í–‰ ìƒí™© í‘œì‹œ (100í”„ë ˆì„ë§ˆë‹¤)
                if is_video_file and total_frames and frame_count % 100 == 0:
                    progress = (frame_count / total_frames) * 100
                    elapsed_time = time.time() - start_time
                    estimated_total = elapsed_time * total_frames / frame_count if frame_count > 0 else 0
                    remaining = max(0, estimated_total - elapsed_time)
                    print(f"ğŸ“Š ì§„í–‰ ìƒí™©: {frame_count}/{total_frames} í”„ë ˆì„ ({progress:.1f}%) - ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {remaining:.1f}ì´ˆ")
                
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # YOLO ê²€ì¶œ
                if self.use_obb:
                    results = self.yolo_model.predict(
                        frame_rgb, 
                        conf=self.conf_threshold,
                        verbose=False,
                        task='obb'
                    )[0]
                else:
                    results = self.yolo_model.predict(
                        frame_rgb, 
                        conf=self.conf_threshold,
                        verbose=False
                    )[0]
                
                # [ìˆ˜ì •ë¨] ê²€ì¶œ ê²°ê³¼ í™•ì¸ ë¡œì§ (OBB ìš°ì„  ìˆœìœ„ ì ìš©)
                boxes = None
                # 1. OBB ëª¨ë“œì´ê³  OBB ê²°ê³¼ê°€ ìˆë‹¤ë©´ ê·¸ê²ƒì„ ìš°ì„ ìˆœìœ„ë¡œ ê°€ì ¸ì˜´
                if self.use_obb and hasattr(results, 'obb') and results.obb is not None:
                    boxes = results.obb
                # 2. ê·¸ ì™¸ì˜ ê²½ìš° ì¼ë°˜ boxesë¥¼ ê°€ì ¸ì˜´
                elif hasattr(results, 'boxes'):
                    boxes = results.boxes
                
                # í™”ë©´ì— í‘œì‹œ
                display_frame = self._draw_detections(frame.copy(), boxes)
                
                # ê²€ì¶œ ì „ìš© ëª¨ë“œì¸ ê²½ìš° YOLO ê²€ì¶œë§Œ ìˆ˜í–‰ (ì¡°ê±´ í™•ì¸, íƒ€ì´ë¨¸, ê²€ì‚¬ ì—†ìŒ)
                if self.detect_only:
                    # ê²€ì¶œëœ ê°ì²´ ê°œìˆ˜ í‘œì‹œ
                    num_detections = len(boxes) if boxes is not None else 0
                    info_text = f"Detections: {num_detections}"
                    cv2.putText(display_frame, info_text, (10, 30),
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
                    
                    # ë¹„ë””ì˜¤ íŒŒì¼ì¸ ê²½ìš° ëª¨ë“  í”„ë ˆì„ì„ ì¶œë ¥ ë¹„ë””ì˜¤ì— ì €ì¥
                    if is_video_file and video_writer and video_writer.isOpened():
                        video_writer.write(display_frame)
                    
                    cv2.imshow('Real-time Inspection', display_frame)
                    
                    # ë¹„ë””ì˜¤ íŒŒì¼ì¸ ê²½ìš° FPSì— ë§ì¶° ì§€ì—° ì‹œê°„ ì¶”ê°€
                    if is_video_file and video_fps:
                        delay_ms = max(1, int(1000.0 / video_fps))
                        key = cv2.waitKey(delay_ms) & 0xFF
                    else:
                        key = cv2.waitKey(1) & 0xFF
                    
                    if key == ord('q'):
                        print("\nì‚¬ìš©ìê°€ ì¢…ë£Œí•¨")
                        break
                    continue  # YOLO ê²€ì¶œë§Œ í•˜ê³  ê³„ì† ì§„í–‰ (ì¡°ê±´ í™•ì¸, íƒ€ì´ë¨¸, ê²€ì‚¬ ê±´ë„ˆëœ€)
                
                # ì¼ë°˜ ëª¨ë“œ: ì¡°ê±´ í™•ì¸ ë° ê²€ì‚¬ ìˆ˜í–‰
                # ë¹„ë””ì˜¤ íŒŒì¼ì¸ ê²½ìš° ëª¨ë“  í”„ë ˆì„ì„ ì¶œë ¥ ë¹„ë””ì˜¤ì— ì €ì¥
                if is_video_file and video_writer and video_writer.isOpened():
                    video_writer.write(display_frame)
                
                # ì¡°ê±´ í™•ì¸
                condition_satisfied, detections = self._check_condition(boxes)
                
                # ì¡°ê±´ ë§Œì¡± ì—¬ë¶€ì— ë”°ë¥¸ ì²˜ë¦¬
                if condition_satisfied:
                    if not self.condition_met:
                        self.condition_met = True
                        self.condition_start_time = time.time()
                        self.condition_start_frame = frame_count if is_video_file else None
                        print(f"âœ“ ì¡°ê±´ ë§Œì¡±! íƒ€ì´ë¨¸ ì‹œì‘...")
                    
                    # ë¹„ë””ì˜¤ íŒŒì¼ì¸ ê²½ìš° í”„ë ˆì„ ê¸°ë°˜ íƒ€ì´ë¨¸, ì¹´ë©”ë¼ëŠ” ì‹œê°„ ê¸°ë°˜ íƒ€ì´ë¨¸
                    if is_video_file and video_fps and self.condition_start_frame is not None:
                        frames_elapsed = frame_count - self.condition_start_frame
                        required_frames = int(self.required_duration * video_fps)
                        elapsed = frames_elapsed / video_fps
                        timer_text = f"Timer: {elapsed:.1f}s / {self.required_duration}s ({frames_elapsed}/{required_frames} frames)"
                        should_inspect = frames_elapsed >= required_frames
                    else:
                        elapsed = time.time() - self.condition_start_time
                        timer_text = f"Timer: {elapsed:.1f}s / {self.required_duration}s"
                        should_inspect = elapsed >= self.required_duration
                    
                    self.last_valid_frame = frame.copy()
                    self.last_valid_detections = detections
                    
                    cv2.putText(display_frame, timer_text, (10, 30),
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    
                    if should_inspect:
                        print(f"\n{'='*60}")
                        print(f"ğŸ“¸ ì¡°ê±´ì´ {self.required_duration}ì´ˆ ì´ìƒ ìœ ì§€ë¨! ê²€ì‚¬ ì‹œì‘...")
                        print(f"{'='*60}\n")
                        
                        # ë¹„ë””ì˜¤ íŒŒì¼ì¸ ê²½ìš° ê²€ì‚¬ í›„ì—ë„ ê³„ì† ì§„í–‰
                        if is_video_file:
                            # ê²€ì‚¬ ìˆ˜í–‰ (í™”ë©´ì€ ë‹«ì§€ ì•ŠìŒ)
                            self._perform_inspection(self.last_valid_frame.copy(), self.last_valid_detections)
                            # íƒ€ì´ë¨¸ ë¦¬ì…‹í•˜ì—¬ ë‹¤ìŒ ì¡°ê±´ ë§Œì¡± ì‹œì—ë„ ê²€ì‚¬ ê°€ëŠ¥
                            self.condition_met = False
                            self.condition_start_time = None
                            self.condition_start_frame = None
                            self.last_valid_frame = None
                            self.last_valid_detections = None
                            print(f"ğŸ“¹ ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ê³„ì† ì§„í–‰ ì¤‘... (í”„ë ˆì„ {frame_count}/{total_frames if total_frames else '?'})\n")
                        else:
                            # ì¹´ë©”ë¼ì¸ ê²½ìš° ê²€ì‚¬ í›„ ì¢…ë£Œ
                            cap.release()
                            cv2.destroyAllWindows()
                            self._perform_inspection(self.last_valid_frame, self.last_valid_detections)
                            return
                else:
                    if self.condition_met:
                        print(f"âš ï¸  ì¡°ê±´ í•´ì œë¨. íƒ€ì´ë¨¸ ë¦¬ì…‹.")
                        self.condition_met = False
                        self.condition_start_time = None
                        self.condition_start_frame = None
                        self.last_valid_frame = None
                        self.last_valid_detections = None
                    
                    status_text = "Waiting for condition..."
                    cv2.putText(display_frame, status_text, (10, 30),
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                
                cv2.imshow('Real-time Inspection', display_frame)
                
                # ë¹„ë””ì˜¤ íŒŒì¼ì¸ ê²½ìš° FPSì— ë§ì¶° ì§€ì—° ì‹œê°„ ì¶”ê°€
                if is_video_file and video_fps:
                    delay_ms = max(1, int(1000.0 / video_fps))
                    key = cv2.waitKey(delay_ms) & 0xFF
                else:
                    key = cv2.waitKey(1) & 0xFF
                
                if key == ord('q'):
                    print("\nì‚¬ìš©ìê°€ ì¢…ë£Œí•¨")
                    break
        
        finally:
            cap.release()
            if video_writer and video_writer.isOpened():
                video_writer.release()
                if output_video_path:
                    # ì €ì¥ëœ íŒŒì¼ í¬ê¸° í™•ì¸
                    import os
                    if os.path.exists(output_video_path):
                        file_size = os.path.getsize(output_video_path) / (1024 * 1024)  # MB
                        print(f"\n{'='*60}")
                        print(f"ğŸ’¾ ë¹„ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {output_video_path}")
                        print(f"   íŒŒì¼ í¬ê¸°: {file_size:.2f} MB")
                        print(f"   ì´ í”„ë ˆì„: {frame_count} í”„ë ˆì„")
                        if total_frames:
                            print(f"   ì›ë³¸ í”„ë ˆì„: {total_frames} í”„ë ˆì„")
                        print(f"{'='*60}\n")
                    else:
                        print(f"\nâš ï¸  ë¹„ë””ì˜¤ íŒŒì¼ì´ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {output_video_path}\n")
            elif is_video_file:
                print(f"\nâš ï¸  ë¹„ë””ì˜¤ Writerê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ë¹„ë””ì˜¤ê°€ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n")
            cv2.destroyAllWindows()
    
    def _check_condition(self, boxes):
        """ì¡°ê±´ í™•ì¸"""
        if boxes is None:
            if self.mode == 'frontdoor':
                return False, {'high': [], 'mid': [], 'low': []}
            else:  # bolt
                return False, {'bolts': [], 'frames': []}
        
        if self.mode == 'frontdoor':
            return self._check_frontdoor_condition(boxes)
        else:  # bolt
            return self._check_bolt_condition(boxes)
    
    def _check_frontdoor_condition(self, boxes):
        """í”„ë¡ íŠ¸ë„ì–´ ì¡°ê±´ í™•ì¸"""
        detections = {'high': [], 'mid': [], 'low': []}
        
        for box in boxes:
            cls_id = int(box.cls[0])
            conf = float(box.conf[0])
            
            # [ìˆ˜ì •ë¨] OBB/ì¼ë°˜ ë°•ìŠ¤ ìë™ íŒë³„ (IndexError ë°©ì§€)
            bbox = None
            if self.use_obb and hasattr(box, 'xyxyxyxy'):
                xyxyxyxy = box.xyxyxyxy[0].cpu().numpy().flatten()        # flatten()ì„ ì¶”ê°€í•˜ì—¬ (4,2) í˜•íƒœë¥¼ (8,)ë¡œ ê°•ì œ ë³€í™˜
                if len(xyxyxyxy) == 8:
                    bbox = xyxyxyxy # 8ê°œ ì  ê·¸ëŒ€ë¡œ ì‚¬ìš©
                else:
                    bbox = xyxyxyxy[:4] # 4ê°œë©´ ì¼ë°˜ ë°•ìŠ¤ì²˜ëŸ¼ ì‚¬ìš©
            
            if bbox is None: # ìœ„ì—ì„œ ì²˜ë¦¬ ì•ˆëìœ¼ë©´ ì¼ë°˜ xyxy
                bbox = box.xyxy[0].cpu().numpy()
            
            class_name = self.yolo_model.names[cls_id].lower()
            if class_name in detections:
                detections[class_name].append({
                    'bbox': bbox,
                    'conf': conf,
                    'cls_id': cls_id
                })
        
        has_all_three = (len(detections['high']) == 1 and 
                        len(detections['mid']) == 1 and 
                        len(detections['low']) == 1)
        has_high_low = (len(detections['high']) == 1 and 
                       len(detections['low']) == 1 and 
                       len(detections['mid']) == 0)
        
        condition_met = has_all_three or has_high_low
        
        return condition_met, detections
    
    def _check_bolt_condition(self, boxes):
        """ë³¼íŠ¸ ì¡°ê±´ í™•ì¸"""
        bolt_detections = []
        frame_detections = []
        
        for box in boxes:
            cls_id = int(box.cls[0])
            conf = float(box.conf[0])
            
            # [ìˆ˜ì •ë¨] OBB/ì¼ë°˜ ë°•ìŠ¤ ìë™ íŒë³„ ë° ì¤‘ì‹¬ì  ê³„ì‚° (IndexError ë°©ì§€)
            bbox = None
            center = None
            
            if self.use_obb and hasattr(box, 'xyxyxyxy'):
                xyxyxyxy = box.xyxyxyxy[0].cpu().numpy().flatten()        # flatten()ì„ ì¶”ê°€í•˜ì—¬ (4,2) ï¿½å½¢íƒœë¥¼ (8,)ë¡œ ê°•ì œ ë³€í™˜
                if len(xyxyxyxy) == 8:
                    # ì§„ì •í•œ OBB
                    center = [xyxyxyxy[::2].mean(), xyxyxyxy[1::2].mean()]
                    bbox = xyxyxyxy
                else:
                    # ë¬´ëŠ¬ë§Œ OBB (ì‹¤ì œë¡  4ì¢Œí‘œ)
                    bbox = xyxyxyxy[:4]
                    center = [(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2]
            
            if bbox is None: # ì¼ë°˜ xyxy
                bbox = box.xyxy[0].cpu().numpy()
                center = [(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2]
            
            detection = {
                'class_id': cls_id,
                'bbox': bbox,
                'conf': conf,
                'center': center
            }
            
            if cls_id in [0, 1]:  # ë³¼íŠ¸
                bolt_detections.append(detection)
            elif cls_id in [2, 3, 4, 5, 6, 7]:  # í”„ë ˆì„
                frame_detections.append(detection)
        
        condition_met = len(frame_detections) == 1
        
        detections = {
            'bolts': bolt_detections,
            'frames': frame_detections
        }
        
        return condition_met, detections
    
    def _draw_detections(self, frame, boxes):
        """ê²€ì¶œ ê²°ê³¼ë¥¼ í”„ë ˆì„ì— ê·¸ë¦¬ê¸°"""
        if boxes is None:
            return frame
        
        for box in boxes:
            cls_id = int(box.cls[0])
            conf = float(box.conf[0])
            
            class_name = self.yolo_model.names[cls_id]
            
            if self.mode == 'frontdoor':
                color = (0, 255, 0) if class_name.lower() in ['high', 'mid', 'low'] else (128, 128, 128)
            else:  # bolt
                if cls_id in [0, 1]:
                    color = (255, 0, 0)
                elif cls_id in [2, 3, 4, 5, 6, 7]:
                    color = (0, 255, 0)
                else:
                    color = (128, 128, 128)
            
            # OBB ë°ì´í„° ê¸¸ì´ í™•ì¸ í›„ ë¶„ê¸° ì²˜ë¦¬ (IndexError ë°©ì§€)
            is_obb_drawn = False
            if self.use_obb and hasattr(box, 'xyxyxyxy'):
                xyxyxyxy = box.xyxyxyxy[0].cpu().numpy().flatten()        # flatten()ì„ ì¶”ê°€í•˜ì—¬ (4,2) í˜•íƒœë¥¼ (8,)ë¡œ ê°•ì œ ë³€í™˜
                
                # ë°ì´í„°ê°€ 8ê°œ(ì  4ê°œ)ì¸ ê²½ìš°ì—ë§Œ OBBë¡œ ê·¸ë¦¬ê¸°
                if len(xyxyxyxy) == 8:
                    points = np.array([
                        [xyxyxyxy[0], xyxyxyxy[1]],
                        [xyxyxyxy[2], xyxyxyxy[3]],
                        [xyxyxyxy[4], xyxyxyxy[5]],
                        [xyxyxyxy[6], xyxyxyxy[7]]
                    ], dtype=np.int32)
                    cv2.polylines(frame, [points], isClosed=True, color=color, thickness=2)
                    x1, y1 = int(points[0][0]), int(points[0][1])
                    is_obb_drawn = True
                else:
                    # OBB ëª¨ë“œì§€ë§Œ ë°ì´í„°ê°€ 4ê°œë¼ë©´ ì¼ë°˜ ë°•ìŠ¤ë¡œ ì·¨ê¸‰
                    x1, y1, x2, y2 = map(int, xyxyxyxy[:4])
                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                    is_obb_drawn = False 
            
            if not is_obb_drawn:
                # ì¼ë°˜ ë°•ìŠ¤ (OBB ì‹¤íŒ¨í–ˆê±°ë‚˜ ëª¨ë“œ ì•„ë‹ ë•Œ)
                if hasattr(box, 'xyxy'):
                    xyxy = box.xyxy[0].cpu().numpy()
                    x1, y1, x2, y2 = map(int, xyxy)
                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                else:
                    continue # ì¢Œí‘œ ì •ë³´ ì—†ìœ¼ë©´ ê±´ë„ˆëœ€

            # ë¼ë²¨ ê·¸ë¦¬ê¸°
            label = f"{class_name}: {conf:.2f}"
            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
            y_label = max(y1, label_size[1] + 10)
            cv2.rectangle(frame, (x1, y_label - label_size[1] - 10), 
                         (x1 + label_size[0], y_label), color, -1)
            cv2.putText(frame, label, (x1, y_label - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        return frame
    
    def _perform_inspection(self, frame, detections):
        """ê²€ì‚¬ ìˆ˜í–‰"""
        if self.mode == 'frontdoor':
            self._inspect_frontdoor(frame, detections)
        else:  # bolt
            self._inspect_bolt(frame, detections)
    
    def _inspect_frontdoor(self, frame, detections):
        """í”„ë¡ íŠ¸ë„ì–´ ê²€ì‚¬"""
        print(f"ğŸ” í”„ë¡ íŠ¸ë„ì–´ ê²€ì‚¬ ì¤‘...\n")
        
        part_results = {}
        parts_to_process = []
        
        if len(detections['high']) == 1 and len(detections['mid']) == 1 and len(detections['low']) == 1:
            parts_to_process = ['high', 'mid', 'low']
        elif len(detections['high']) == 1 and len(detections['low']) == 1 and len(detections['mid']) == 0:
            parts_to_process = ['high', 'low']
        
        for part in parts_to_process:
            if len(detections[part]) > 0:
                bbox = detections[part][0]['bbox']
                
                # OBB ëª¨ë“œì¸ ê²½ìš° íšŒì „ëœ ê°ì²´ crop
                # bboxê°€ 8ê°œ ì¢Œí‘œë¥¼ ê°€ì§„ ì§„ì§œ OBBì¼ë•Œë§Œ íšŒì „ í¬ë¡­ ì‹œë„
                if self.use_obb and len(bbox) == 8:
                    cropped = self._crop_obb_object(frame, bbox)
                else:
                    x1, y1, x2, y2 = map(int, bbox[:4]) # 4ê°œë§Œ ì‚¬ìš©
                    cropped = frame[y1:y2, x1:x2]
                
                if cropped is None or cropped.size == 0:
                    print(f"  [{part.upper()}] í¬ë¡­ ì‹¤íŒ¨")
                    continue
                
                # í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥ (ë””ë²„ê¹…ìš©)
                if self.debug and self.debug_crop_dir:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]  # ë°€ë¦¬ì´ˆ í¬í•¨
                    crop_filename = f"{self.debug_crop_dir}/frontdoor_{part}_{timestamp}.jpg"
                    cv2.imwrite(crop_filename, cropped)
                    print(f"  [{part.upper()}] í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥: {crop_filename} (í¬ê¸°: {cropped.shape[1]}x{cropped.shape[0]})")
                
                result = self._classify_with_dino(cropped, part)
                part_results[part] = result
                
                if result['num_classes'] == 4:
                    result_text = "ì–‘í’ˆ" if not result['is_defect'] else f"ë¶ˆëŸ‰(í´ë˜ìŠ¤ {result['pred_class']})"
                    conf_display = result['confidence'][result['pred_class']]
                else:
                    result_text = "ì–‘í’ˆ" if not result['is_defect'] else "ë¶ˆëŸ‰"
                    conf_display = result['confidence'][result['pred_class']]
                
                print(f"  [{part.upper()}] {result_text} (ì‹ ë¢°ë„: {conf_display:.2%})")
        
        print(f"\nğŸ“Š ìµœì¢… íŒì • ({self.voting_method.upper()} Voting):")
        if self.voting_method == 'hard':
            final_result = self._hard_voting(part_results)
        else:
            final_result = self._soft_voting(part_results)
        
        print(f"  ê²°ê³¼: {'âœ… ì–‘í’ˆ' if final_result == 'good' else 'âŒ ë¶ˆëŸ‰'}")
        print(f"\n{'='*60}\n")
    
    def _inspect_bolt(self, frame, detections):
        """ë³¼íŠ¸ ê²€ì‚¬"""
        print(f"ğŸ” ë³¼íŠ¸ ê²€ì‚¬ ì¤‘...\n")
        
        frame_obj = detections['frames'][0]
        frame_bbox = frame_obj['bbox']
        frame_cls = frame_obj['class_id']
        
        frame_name = self.bolt_class_names.get(frame_cls, 'unknown')
        print(f"  í”„ë ˆì„ íƒ€ì…: {frame_name}")
        
        bolts_in_frame = []
        for bolt in detections['bolts']:
            cx, cy = bolt['center']
            if self.use_obb and len(frame_bbox) == 8:
                if self._point_in_obb(cx, cy, frame_bbox):
                    bolts_in_frame.append(bolt)
            else:
                # ì¼ë°˜ bbox (ë˜ëŠ” 4ì¢Œí‘œ OBB)
                if (frame_bbox[0] <= cx <= frame_bbox[2] and 
                    frame_bbox[1] <= cy <= frame_bbox[3]):
                    bolts_in_frame.append(bolt)
        
        print(f"  í”„ë ˆì„ ë‚´ ë³¼íŠ¸ ê°œìˆ˜: {len(bolts_in_frame)}")
        
        if frame_cls in [2, 3, 4]:
            if len(bolts_in_frame) != 2:
                print(f"\nğŸ“Š ìµœì¢… íŒì •:")
                print(f"  ê²°ê³¼: âŒ ë¶ˆëŸ‰ (ë³¼íŠ¸ ê°œìˆ˜ ë¶ˆì¼ì¹˜: {len(bolts_in_frame)}/2)")
                print(f"\n{'='*60}\n")
                return
        
        if len(bolts_in_frame) == 0:
            print(f"\nğŸ“Š ìµœì¢… íŒì •:")
            print(f"  ê²°ê³¼: âŒ ë¶ˆëŸ‰ (í”„ë ˆì„ ë‚´ ë³¼íŠ¸ ì—†ìŒ)")
            print(f"\n{'='*60}\n")
            return
        
        print(f"\n  ë³¼íŠ¸ë³„ ê²€ì‚¬:")
        bolt_results = []
        for i, bolt in enumerate(bolts_in_frame):
            bbox = bolt['bbox']
            
            if self.use_obb and len(bbox) == 8:
                cropped = self._crop_obb_object(frame, bbox)
            else:
                x1, y1, x2, y2 = map(int, bbox[:4])
                cropped = frame[y1:y2, x1:x2]
            
            if cropped is None or cropped.size == 0:
                print(f"    ë³¼íŠ¸ #{i+1}: í¬ë¡­ ì‹¤íŒ¨")
                continue
            
            # í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥ (ë””ë²„ê¹…ìš©)
            if self.debug and self.debug_crop_dir:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                crop_filename = f"{self.debug_crop_dir}/bolt_{i+1}_{frame_name}_{timestamp}.jpg"
                cv2.imwrite(crop_filename, cropped)
                print(f"    ë³¼íŠ¸ #{i+1}: í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥: {crop_filename} (í¬ê¸°: {cropped.shape[1]}x{cropped.shape[0]})")
            
            result = self._classify_with_dino(cropped, 'bolt')
            bolt_results.append(result)
            
            result_text = "ì–‘í’ˆ" if not result['is_defect'] else "ë¶ˆëŸ‰"
            conf_display = result['confidence'][result['pred_class']]
            
            print(f"    ë³¼íŠ¸ #{i+1}: {result_text} (ì‹ ë¢°ë„: {conf_display:.2%})")
        
        print(f"\nğŸ“Š ìµœì¢… íŒì • ({self.voting_method.upper()} Voting):")
        if self.voting_method == 'hard':
            final_result = self._hard_voting_bolt(bolt_results)
        else:
            final_result = self._soft_voting_bolt(bolt_results)
        
        print(f"  ê²°ê³¼: {'âœ… ì–‘í’ˆ' if final_result == 'good' else 'âŒ ë¶ˆëŸ‰'}")
        print(f"\n{'='*60}\n")
    
    def _classify_with_dino(self, cropped_img, part):
        """DINOv2ë¡œ ë¶„ë¥˜"""
        is_bolt = (part == 'bolt')
        num_classes = 2 if is_bolt else self.dino_num_classes.get(part, 2)
        
        if cropped_img.size == 0:
            if num_classes == 4:
                confidence = [0.0, 0.0, 0.0, 1.0]
                defect_confidence = 1.0
                pred_class = 3
            else:
                confidence = [0.0, 1.0]
                defect_confidence = 1.0
                pred_class = 1
            return {
                'is_defect': True,
                'confidence': confidence,
                'pred_class': pred_class,
                'defect_confidence': defect_confidence,
                'num_classes': num_classes
            }
        
        cropped_rgb = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB)
        pil_img = Image.fromarray(cropped_rgb)
        
        img_tensor = self.transform(pil_img).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            outputs = self.dino_models[part](img_tensor)
            probs = torch.softmax(outputs, dim=1)
            pred_class = torch.argmax(probs, dim=1).item()
            confidence = probs[0].cpu().numpy().tolist()
        
        if num_classes == 4:
            is_defect = (pred_class != 0)
            defect_confidence = sum(confidence[1:4]) if len(confidence) >= 4 else confidence[1] if len(confidence) >= 2 else 0.0
        else:
            is_defect = (pred_class == 1)
            defect_confidence = confidence[1] if len(confidence) >= 2 else 0.0
        
        return {
            'is_defect': is_defect,
            'confidence': confidence,
            'pred_class': pred_class,
            'defect_confidence': defect_confidence,
            'num_classes': num_classes
        }
    
    def _hard_voting(self, part_results):
        has_defect = any(result['is_defect'] for result in part_results.values())
        return 'defect' if has_defect else 'good'
    
    def _soft_voting(self, part_results):
        if len(part_results) == 0:
            return 'good'
        defect_confidences = [result['defect_confidence'] for result in part_results.values()]
        avg_defect_conf = sum(defect_confidences) / len(defect_confidences)
        return 'defect' if avg_defect_conf >= 0.5 else 'good'
    
    def _hard_voting_bolt(self, bolt_results):
        if len(bolt_results) == 0:
            return 'good'
        has_defect = any(b['is_defect'] for b in bolt_results)
        return 'defect' if has_defect else 'good'
    
    def _soft_voting_bolt(self, bolt_results):
        if len(bolt_results) == 0:
            return 'good'
        defect_confidences = [b['defect_confidence'] for b in bolt_results]
        avg_defect_conf = sum(defect_confidences) / len(defect_confidences)
        return 'defect' if avg_defect_conf >= 0.5 else 'good'
    
    def _point_in_obb(self, x, y, obb_points):
        if len(obb_points) != 8:
            return False
        points = [(obb_points[i], obb_points[i+1]) for i in range(0, 8, 2)]
        n = len(points)
        inside = False
        j = n - 1
        for i in range(n):
            xi, yi = points[i]
            xj, yj = points[j]
            if ((yi > y) != (yj > y)) and (x < (xj - xi) * (y - yi) / (yj - yi) + xi):
                inside = not inside
            j = i
        return inside
    
    def _compute_rotated_box_corners(self, cx, cy, w, h, angle):
        dx = w / 2.0
        dy = h / 2.0
        local_corners = [(-dx, -dy), (dx, -dy), (dx, dy), (-dx, dy)]
        c = cos(angle)
        s = sin(angle)
        corners = []
        for lx, ly in local_corners:
            rx = c * lx - s * ly + cx
            ry = s * lx + c * ly + cy
            corners.append((rx, ry))
        return corners
    
    def _correct_orientation_constrained(self, w, h, angle):
        pi = math.pi
        angle = (angle + pi) % (2 * pi) - pi
        if w >= h:
            if abs(angle) > pi / 2:
                angle -= pi
        else:
            if angle > 0:
                angle -= pi
            if angle < -pi + (pi/4):
                angle += pi
        angle = (angle + pi) % (2 * pi) - pi
        return w, h, angle
    
    def _crop_obb_object(self, img, obb_points):
        if len(obb_points) != 8:
            return None
        img_h, img_w = img.shape[:2]
        points = np.array([
            [obb_points[0], obb_points[1]],
            [obb_points[2], obb_points[3]],
            [obb_points[4], obb_points[5]],
            [obb_points[6], obb_points[7]]
        ], dtype=np.float32)
        cx = points[:, 0].mean()
        cy = points[:, 1].mean()
        w = np.linalg.norm(points[1] - points[0])
        h = np.linalg.norm(points[2] - points[1])
        vx = points[1][0] - points[0][0]
        vy = points[1][1] - points[0][1]
        angle = math.atan2(vy, vx)
        w, h, angle = self._correct_orientation_constrained(w, h, angle)
        
        if abs(angle) < 1e-6:
            x1 = max(0, int(cx - w / 2))
            y1 = max(0, int(cy - h / 2))
            x2 = min(img_w, int(cx + w / 2))
            y2 = min(img_h, int(cy + h / 2))
            if x1 >= x2 or y1 >= y2:
                return None
            crop = img[y1:y2, x1:x2]
            crop_resized = cv2.resize(crop, (int(w), int(h)), interpolation=cv2.INTER_LINEAR)
            return crop_resized
        
        src_corners = self._compute_rotated_box_corners(cx, cy, w, h, angle)
        src_points = np.array(src_corners, dtype=np.float32)
        dst_corners = [(0, 0), (w, 0), (w, h), (0, h)]
        dst_points = np.array(dst_corners, dtype=np.float32)
        M = cv2.getPerspectiveTransform(src_points, dst_points)
        warped = cv2.warpPerspective(img, M, (int(w), int(h)), 
                                      flags=cv2.INTER_LINEAR,
                                      borderMode=cv2.BORDER_CONSTANT,
                                      borderValue=(0, 0, 0))
        return warped


def load_config(config_path):
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    required_keys = ['mode', 'yolo_model']
    for key in required_keys:
        if key not in config:
            raise ValueError(f"ì„¤ì • íŒŒì¼ì— '{key}' í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤")
    return config


def main():
    parser = argparse.ArgumentParser(description='ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ì–‘ë¶ˆëŸ‰ ê²€ì‚¬ ì‹œìŠ¤í…œ')
    parser.add_argument('--config', type=str, required=True, help='ì„¤ì • YAML íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--source', type=str, default='0', help='ì¹´ë©”ë¼ ì†ŒìŠ¤ (0: ì›¹ìº , RTSP URL ë“±, ê¸°ë³¸ê°’: 0)')
    parser.add_argument('--device', type=str, default='cuda', choices=['cuda', 'cpu'], help='ë””ë°”ì´ìŠ¤ (ê¸°ë³¸ê°’: cuda)')
    parser.add_argument('--obb', action='store_true', help='OBB(Oriented Bounding Box) ëª¨ë“œ ì‚¬ìš©')
    parser.add_argument('--debug', action='store_true', help='ë””ë²„ê·¸ ëª¨ë“œ: í¬ë¡­ ì´ë¯¸ì§€ë¥¼ debug_crops í´ë”ì— ì €ì¥')
    parser.add_argument('--detect-only', action='store_true', help='ê²€ì¶œ ì „ìš© ëª¨ë“œ: YOLO ê²€ì¶œë§Œ ìˆ˜í–‰í•˜ê³  ê²€ì‚¬ëŠ” í•˜ì§€ ì•ŠìŒ')
    
    args = parser.parse_args()
    config = load_config(args.config)
    
    mode = config['mode'].lower()
    yolo_model = config['yolo_model']
    conf_threshold = config.get('conf_threshold', 0.25)
    dino_mode = config.get('dino_mode', 'simple')
    
    dino_models = {}
    if mode == 'frontdoor':
        dino_models = {
            'high': config['dino_high'],
            'mid': config['dino_mid'],
            'low': config['dino_low']
        }
        voting_method = config.get('voting_method', 'soft')
    else:
        dino_models = {'bolt': config['dino_bolt']}
        voting_method = config.get('voting_method', 'soft')
    
    try:
        source = int(args.source)
    except ValueError:
        source = args.source
    
    system = RealtimeInspectionSystem(
        mode=mode,
        yolo_model_path=yolo_model,
        dino_models=dino_models,
        device=args.device,
        conf_threshold=conf_threshold,
        voting_method=voting_method,
        use_obb=args.obb,
        debug=args.debug,
        detect_only=args.detect_only
    )
    
    system.dino_mode = dino_mode
    system.run(source=source)


if __name__ == "__main__":
    main()